---
title: 'Grammar Induction: Beyond Local Search'
abstract: Many approaches to probabilistic grammar induction operate by iteratively
  improving a single grammar, beginning with an initial guess. These local search
  paradigms include (variational) EM, MCMC, and greedy model merging or splitting
  procedures.  Unfortunately, local search methods tend to get caught in local optima,
  even with random restarts.  Two approaches are outlined that try to avoid this problem.  One
  uses branch-and-bound methods from mathematical programming to eliminate regions
  of parameter space that cannot contain the global optimum.  The other is inspired
  by recent work on deep learning, and uses spectral methods to build up featural
  representations of all substrings, without premature commitment to which substrings
  are constituents.
pdf: http://proceedings.mlr.press/v21/eisner12a/eisner12a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: eisner12a
month: 0
tex_title: 'Grammar Induction: Beyond Local Search'
firstpage: 112
lastpage: 113
page: 112-113
order: 112
cycles: false
author:
- given: Jason
  family: Eisner
date: 2012-08-16
address: University of Maryland, College Park, MD, USA
publisher: PMLR
container-title: Proceedings of the Eleventh International Conference on Grammatical
  Inference
volume: '21'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 8
  - 16
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
